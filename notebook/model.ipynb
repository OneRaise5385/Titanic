{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train_final.csv')\n",
    "test = pd.read_csv('../input/test_final.csv')\n",
    "\n",
    "X = train.drop(['Survived'], axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "\n",
    "def save_model(model, name):\n",
    "    '''保存模型'''\n",
    "    joblib.dump(model, f'../models/{name}.pkl')\n",
    "    print(f'{name} is successfully saved!')\n",
    "    return True\n",
    "\n",
    "\n",
    "def submit(model_name : str,\n",
    "           test : pd.DataFrame):\n",
    "    ''' \n",
    "    保存提交（预测）的数据\\n\n",
    "    model_name: 模型的名称（只传入点号之前的名称）\\n\n",
    "    test: 需要预测的数据集\n",
    "    '''\n",
    "    # 载入模型\n",
    "    model = joblib.load(f'../models/{model_name}.pkl')\n",
    "    # 使用模型预测\n",
    "    y_pred = model.predict(test)\n",
    "    # 保存提交\n",
    "    submission = pd.read_csv('../submission/submission.csv')\n",
    "    submission['Survived'] = y_pred.astype(int)\n",
    "    submission.to_csv(f'../submission/{model_name}.csv', index=None)\n",
    "    print(f'{model_name} is successfully used to test!')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "RandomForest Best Params:  {'criterion': 'entropy', 'max_depth': 10, 'max_features': 0.5, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "RandomForest Best Score:  0.8451133011110414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def best_randomforest_clf(X : pd.DataFrame,\n",
    "                          y : pd.DataFrame, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_estimators = 100,  # 树不断增加，一般认为就不会过拟合，尽量增加树的棵树\n",
    "                          min_weight_fraction_leaf = 0,\n",
    "                          min_impurity_decrease=[0.0],\n",
    "                          bootstrap = True,\n",
    "                          oob_score = False,\n",
    "                          class_weight = None):\n",
    "    '''\n",
    "    ***随机森林*** 分类器模型寻优\\n\n",
    "    X：输入模型的特征\\n\n",
    "    y：输入模型的标签\\n\n",
    "    scoring：模型的评价标准，可取的值为 ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\\n\n",
    "    min_weight_fraction_leaf: 叶子节点的最小样本数\\n\n",
    "    min_impurity_decrease: 最小不纯度减少量\\n\n",
    "    bootstrap：是否使用有放回抽样\\n\n",
    "    oob_score: 袋外样本评估模型\\n\n",
    "    class_weight: 类别权重默认为None，可选 ['balanced']\\n\n",
    "    return: 输出最佳的随机森林模型\n",
    "    '''\n",
    "    # 参数网格\n",
    "    param_grid = {\"criterion\": [\"gini\", \"entropy\", 'log_loss'],\n",
    "                  'max_depth': [None, 10, 20, 30],\n",
    "                  'min_samples_split': [2, 5, 10],\n",
    "                  'min_samples_leaf': [1, 2, 4],\n",
    "                  'max_features': [None, \"sqrt\", \"log2\", 0.5],\n",
    "                  \"max_leaf_nodes\": [None, 10, 20],\n",
    "                  \"min_impurity_decrease\": min_impurity_decrease,}\n",
    "    # 模型\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                   bootstrap=bootstrap,\n",
    "                                   oob_score=oob_score,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=42,\n",
    "                                   class_weight=class_weight)\n",
    "    \n",
    "    # 使用GridSearchCV进行超参数调优\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring=scoring, \n",
    "                               n_jobs=-1, cv=5, verbose=2)\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # 打印最佳参数和得分\n",
    "    print(f'RandomForest Best Params: ',grid_search.best_params_)\n",
    "    print(f'RandomForest Best Score: ', grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n"
     ]
    }
   ],
   "source": [
    "randomforest = best_randomforest_clf(X, y, scoring='accuracy')\n",
    "save_model(randomforest, 'randomforest')\n",
    "submit('randomforest', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 58320 candidates, totalling 291600 fits\n",
      "DecisionTree Best Params:  {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 0.5, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'random'}\n",
      "DecisionTree Best Score:  0.8383654510074697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def best_decisiontree_clf(X : pd.DataFrame,\n",
    "                          y : pd.DataFrame, \n",
    "                          scoring='accuracy'):\n",
    "    '''\n",
    "    ***决策树*** 分类器模型寻优\\n\n",
    "    X：输入模型的特征\\n\n",
    "    y：输入模型的标签\\n\n",
    "    scoring：模型的评价标准，可取的值为 ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\\n\n",
    "    return: 输出最佳的决策树模型\n",
    "    '''\n",
    "    model = RandomForestClassifier()\n",
    "    # 参数网格\n",
    "    param_grid = {\"criterion\": [\"gini\", \"entropy\", 'log_loss'],  # 分裂标准\n",
    "                  \"splitter\": [\"best\", \"random\"],    # 分裂策略\n",
    "                  \"max_depth\": [None, 3, 5, 10],     # 树的最大深度\n",
    "                  \"min_samples_split\": [2, 5, 10],   # 节点分裂的最小样本数\n",
    "                  \"min_samples_leaf\": [1, 2, 5],     # 叶子节点的最小样本数\n",
    "                  \"min_weight_fraction_leaf\": [0.0],  # 叶子节点的最小权重比例 (样本不平衡时用)\n",
    "                  \"max_features\": [None, 'auto',\"sqrt\", \"log2\", 0.5],  # 分裂时考虑的最大特征数\n",
    "                  \"max_leaf_nodes\": [None, 10, 20],  # 最大叶子节点数\n",
    "                  \"min_impurity_decrease\": [0.0, 0.01, 0.1],  # 最小不纯度减少量\n",
    "                  \"class_weight\": [None, \"balanced\"],  # 类别权重\n",
    "                  \"ccp_alpha\": [0.0, 0.01, 0.1]}     # 代价复杂度剪枝参数\n",
    "    # 模型\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    \n",
    "    # 使用GridSearchCV进行超参数调优\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring=scoring, \n",
    "                               n_jobs=-1, cv=5, verbose=2)\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # 打印最佳参数和得分\n",
    "    print(f'DecisionTree Best Params: ',grid_search.best_params_)\n",
    "    print(f'DecisionTree Best Score: ', grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree = best_decisiontree_clf(X, y, scoring='accuracy')\n",
    "save_model(decisiontree, 'decissiontree')\n",
    "\n",
    "submit('decissiontree', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_rbf Best Params:  {'C': 0.5, 'coef0': 0, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "svc_rbf Best Score:  0.8338773460548616\n",
      "svc_linear Best Params:  {'C': 0.05, 'coef0': 0, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "svc_linear Best Score:  0.8282656455966355\n",
      "svc_poly Best Params:  {'C': 0.025, 'coef0': 1, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "svc_poly Best Score:  0.8372418555018518\n",
      "svc_sigmoid Best Params:  {'C': 0.1, 'coef0': 0.1, 'degree': 2, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "svc_sigmoid Best Score:  0.7654321762601218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/svc_sigmoid.pkl']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_svm_clf(X : pd.DataFrame,\n",
    "             y : pd.DataFrame, \n",
    "             scoring='accuracy',\n",
    "             kernel = 'rbf'):\n",
    "    '''\n",
    "    SVC参数寻优\\n\n",
    "    X：输入模型的特征\\n\n",
    "    y：输入模型的标签\\n\n",
    "    kernel：选择使用哪种和函数，取值为 ['rbf', 'linear', 'poly', 'sigmoid']\\n\n",
    "    scoring：模型的评价标准，可取的值为 ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    return: 输出最佳的模型\n",
    "    '''\n",
    "    # 定义参数网格\n",
    "    param_grid = {'C': [0.025, 0.05, 0.1, 0.5, 1, 10],\n",
    "                'kernel': [kernel],\n",
    "                'degree': [2, 3, 4],\n",
    "                'gamma': ['scale', 'auto'],\n",
    "                'coef0': [0, 0.1, 0.5, 1]}\n",
    "    model = SVC()\n",
    "\n",
    "    # 使用GridSearchCV进行超参数调优\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring=scoring, \n",
    "                               n_jobs=-1, cv=5)\n",
    "    grid_search.fit(X, y)\n",
    "    print(f'svc_{kernel} Best Params: ',grid_search.best_params_)\n",
    "    print(f'svc_{kernel} Best Score: ', grid_search.best_score_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# SVC\n",
    "svc_rbf = best_svm_clf(X, y, scoring='accuracy', kernel='rbf')\n",
    "svc_linear = best_svm_clf(X, y, scoring='accuracy', kernel='linear')\n",
    "svc_poly = best_svm_clf(X, y, scoring='accuracy', kernel='poly')\n",
    "svc_sigmoid = best_svm_clf(X, y, scoring='accuracy', kernel='sigmoid')\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(svc_rbf, '../models/svc_rbf.pkl')\n",
    "joblib.dump(svc_linear, '../models/svc_linear.pkl')\n",
    "joblib.dump(svc_poly, '../models/svc_poly.pkl')\n",
    "joblib.dump(svc_sigmoid, '../models/svc_sigmoid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "submit('svc_linear', test)\n",
    "submit('svc_poly', test)\n",
    "submit('svc_rbf', test)\n",
    "submit('svc_sigmoid', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
